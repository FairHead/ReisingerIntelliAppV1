name: Copilot Usage Analytics

on:
  schedule:
    - cron: '0 8 * * 1'  # Weekly on Mondays at 8 AM
  workflow_dispatch:
  push:
    branches: [main]
    paths:
      - '**/*.cs'
      - '**/*.xaml'

env:
  DOTNET_VERSION: '8.0.x'

jobs:
  analyze-copilot-usage:
    name: Analyze Copilot Usage
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for analysis

    - name: Setup Node.js for analysis scripts
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Analyze commit patterns
      id: commit-analysis
      run: |
        echo "Analyzing commit patterns for Copilot usage..."
        
        # Count commits with Copilot indicators
        copilot_commits=$(git log --oneline --since="30 days ago" | grep -i -E "(copilot|generated|ai-assisted)" | wc -l)
        total_commits=$(git log --oneline --since="30 days ago" | wc -l)
        
        echo "copilot-commits=$copilot_commits" >> $GITHUB_OUTPUT
        echo "total-commits=$total_commits" >> $GITHUB_OUTPUT
        
        if [ $total_commits -gt 0 ]; then
          percentage=$((copilot_commits * 100 / total_commits))
          echo "copilot-percentage=$percentage" >> $GITHUB_OUTPUT
        else
          echo "copilot-percentage=0" >> $GITHUB_OUTPUT
        fi

    - name: Analyze code patterns
      id: code-analysis
      run: |
        echo "Analyzing code patterns that suggest Copilot usage..."
        
        # Look for common Copilot patterns in recent commits
        recent_files=$(git diff --name-only HEAD~10..HEAD | grep -E "\.(cs|xaml)$" || echo "")
        
        copilot_patterns=0
        total_files=0
        
        if [ -n "$recent_files" ]; then
          for file in $recent_files; do
            if [ -f "$file" ]; then
              total_files=$((total_files + 1))
              
              # Check for patterns that suggest Copilot generation
              if grep -q -E "(// Generated by|// Copilot|// AI-generated)" "$file" 2>/dev/null; then
                copilot_patterns=$((copilot_patterns + 1))
              fi
              
              # Check for very consistent/perfect code patterns
              if grep -q -E "(async Task<.*>.*Async\(|ObservableProperty|RelayCommand)" "$file" 2>/dev/null; then
                # These patterns suggest good MAUI/MVVM practices that Copilot helps with
                :
              fi
            fi
          done
        fi
        
        echo "files-with-patterns=$copilot_patterns" >> $GITHUB_OUTPUT
        echo "total-analyzed-files=$total_files" >> $GITHUB_OUTPUT

    - name: Check Copilot configuration effectiveness
      id: config-check
      run: |
        echo "Checking Copilot configuration effectiveness..."
        
        config_score=0
        max_score=10
        
        # Check for essential Copilot files
        if [ -f ".github/copilot-instructions.md" ]; then
          config_score=$((config_score + 3))
          echo "✅ Copilot instructions found"
        fi
        
        if [ -f ".vscode/settings.json" ]; then
          config_score=$((config_score + 2))
          echo "✅ VS Code settings found"
        fi
        
        if [ -f ".vscode/extensions.json" ]; then
          config_score=$((config_score + 1))
          echo "✅ Extensions recommendations found"
        fi
        
        # Check for good code structure (helps Copilot)
        if find . -name "*.cs" -path "*/Services/*" | head -1 | xargs grep -l "async Task" >/dev/null 2>&1; then
          config_score=$((config_score + 2))
          echo "✅ Good async patterns found"
        fi
        
        if find . -name "*.cs" -path "*/Model/*" | head -1 >/dev/null 2>&1; then
          config_score=$((config_score + 1))
          echo "✅ Good project structure found"
        fi
        
        if grep -r "ObservableProperty\|RelayCommand" . --include="*.cs" >/dev/null 2>&1; then
          config_score=$((config_score + 1))
          echo "✅ MVVM patterns found"
        fi
        
        effectiveness=$((config_score * 100 / max_score))
        echo "config-effectiveness=$effectiveness" >> $GITHUB_OUTPUT
        echo "config-score=$config_score" >> $GITHUB_OUTPUT

    - name: Analyze code quality trends
      id: quality-trends
      run: |
        echo "Analyzing code quality trends..."
        
        # Check recent code quality indicators
        cs_files=$(find . -name "*.cs" -not -path "*/bin/*" -not -path "*/obj/*" | wc -l)
        documented_methods=$(grep -r "///" . --include="*.cs" | wc -l)
        
        if [ $cs_files -gt 0 ]; then
          doc_ratio=$((documented_methods * 100 / cs_files))
        else
          doc_ratio=0
        fi
        
        echo "cs-files=$cs_files" >> $GITHUB_OUTPUT
        echo "documented-methods=$documented_methods" >> $GITHUB_OUTPUT
        echo "documentation-ratio=$doc_ratio" >> $GITHUB_OUTPUT
        
        # Check for consistent naming
        inconsistent_naming=$(find . -name "*.cs" -not -path "*/bin/*" -not -path "*/obj/*" -exec basename {} \; | grep -E "(temp|test|new|copy|backup)" | wc -l)
        echo "inconsistent-naming=$inconsistent_naming" >> $GITHUB_OUTPUT

    - name: Generate Copilot effectiveness report
      run: |
        cat > copilot-report.md << 'EOF'
        # GitHub Copilot Usage Analytics Report
        
        Generated on: $(date)
        
        ## Summary
        
        ### Commit Analysis (Last 30 Days)
        - **Total Commits**: ${{ steps.commit-analysis.outputs.total-commits }}
        - **Copilot-related Commits**: ${{ steps.commit-analysis.outputs.copilot-commits }}
        - **Copilot Usage Percentage**: ${{ steps.commit-analysis.outputs.copilot-percentage }}%
        
        ### Code Pattern Analysis
        - **Files Analyzed**: ${{ steps.code-analysis.outputs.total-analyzed-files }}
        - **Files with Copilot Patterns**: ${{ steps.code-analysis.outputs.files-with-patterns }}
        
        ### Configuration Effectiveness
        - **Configuration Score**: ${{ steps.config-check.outputs.config-score }}/10
        - **Effectiveness**: ${{ steps.config-check.outputs.config-effectiveness }}%
        
        ### Code Quality Metrics
        - **C# Files**: ${{ steps.quality-trends.outputs.cs-files }}
        - **Documented Methods**: ${{ steps.quality-trends.outputs.documented-methods }}
        - **Documentation Ratio**: ${{ steps.quality-trends.outputs.documentation-ratio }}%
        - **Files with Inconsistent Naming**: ${{ steps.quality-trends.outputs.inconsistent-naming }}
        
        ## Recommendations
        
        ### High Priority
        - [ ] Review Copilot configuration if effectiveness < 70%
        - [ ] Improve documentation if ratio < 50%
        - [ ] Address inconsistent naming if > 5 files found
        
        ### Medium Priority
        - [ ] Analyze successful Copilot patterns for replication
        - [ ] Update Copilot instructions based on usage patterns
        - [ ] Train team on effective Copilot usage
        
        ### Low Priority
        - [ ] Monitor trends over time
        - [ ] Gather team feedback on Copilot effectiveness
        - [ ] Optimize project structure for better Copilot suggestions
        
        ## Action Items
        
        Based on the analysis, consider:
        
        1. **If Copilot usage is low (< 20%)**:
           - Review team training needs
           - Check if Copilot is properly configured
           - Assess barriers to adoption
        
        2. **If configuration effectiveness is low (< 70%)**:
           - Update `.github/copilot-instructions.md`
           - Improve code commenting and structure
           - Add more descriptive naming
        
        3. **If code quality metrics are declining**:
           - Emphasize code review for Copilot-generated code
           - Update team guidelines
           - Consider additional linting rules
        
        ## Trend Analysis
        
        This report should be generated weekly to track:
        - Copilot adoption trends
        - Code quality improvements
        - Configuration effectiveness over time
        - Team productivity metrics
        
        ---
        *Report generated automatically by GitHub Actions*
        EOF

    - name: Check for existing analytics issue
      id: check-issue
      uses: actions/github-script@v7
      with:
        script: |
          const { data: issues } = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: 'copilot,analytics',
            state: 'open'
          });
          
          return issues.length > 0 ? issues[0].number : null;

    - name: Create or update analytics issue
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('copilot-report.md', 'utf8');
          const existingIssue = ${{ steps.check-issue.outputs.result }};
          
          const issueBody = `## 📊 Weekly Copilot Analytics Report
          
          ${report}
          
          ### Quick Actions
          - [ ] Review this week's metrics
          - [ ] Compare with previous week's trends
          - [ ] Address any declining metrics
          - [ ] Update team on findings
          
          ---
          *Updated automatically every Monday. Close this issue when reviewed.*`;
          
          if (existingIssue) {
            // Update existing issue
            await github.rest.issues.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: existingIssue,
              title: `📊 Copilot Analytics Report - Week of ${new Date().toISOString().split('T')[0]}`,
              body: issueBody
            });
            
            // Add comment about the update
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: existingIssue,
              body: '🔄 Report updated with latest analytics data.'
            });
          } else {
            // Create new issue
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `📊 Copilot Analytics Report - Week of ${new Date().toISOString().split('T')[0]}`,
              body: issueBody,
              labels: ['copilot', 'analytics', 'weekly-report']
            });
          }

    - name: Upload detailed report
      uses: actions/upload-artifact@v4
      with:
        name: copilot-analytics-report
        path: copilot-report.md
        retention-days: 30

    - name: Add summary to workflow
      run: |
        echo "## 📊 Copilot Analytics Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "- **Copilot Usage**: ${{ steps.commit-analysis.outputs.copilot-percentage }}% of commits" >> $GITHUB_STEP_SUMMARY
        echo "- **Config Effectiveness**: ${{ steps.config-check.outputs.config-effectiveness }}%" >> $GITHUB_STEP_SUMMARY
        echo "- **Documentation Ratio**: ${{ steps.quality-trends.outputs.documentation-ratio }}%" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Add recommendations based on metrics
        if [ ${{ steps.config-check.outputs.config-effectiveness }} -lt 70 ]; then
          echo "⚠️ **Action Needed**: Copilot configuration effectiveness is below 70%" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ ${{ steps.quality-trends.outputs.documentation-ratio }} -lt 50 ]; then
          echo "⚠️ **Action Needed**: Documentation ratio is below 50%" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ ${{ steps.commit-analysis.outputs.copilot-percentage }} -lt 20 ]; then
          echo "⚠️ **Action Needed**: Copilot usage is below 20%" >> $GITHUB_STEP_SUMMARY
        fi

  track-team-feedback:
    name: Track Team Feedback
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Analyze Copilot feedback issues
      uses: actions/github-script@v7
      with:
        script: |
          const { data: issues } = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: 'copilot,feedback',
            state: 'all',
            per_page: 100
          });
          
          let positiveCount = 0;
          let negativeCount = 0;
          let totalFeedback = issues.length;
          
          issues.forEach(issue => {
            const body = issue.body.toLowerCase();
            if (body.includes('helpful') || body.includes('excellent') || body.includes('good')) {
              positiveCount++;
            } else if (body.includes('poor') || body.includes('not helpful') || body.includes('bad')) {
              negativeCount++;
            }
          });
          
          console.log(`Total feedback: ${totalFeedback}`);
          console.log(`Positive feedback: ${positiveCount}`);
          console.log(`Negative feedback: ${negativeCount}`);
          
          // Store in environment for next step
          require('fs').writeFileSync('feedback-stats.json', JSON.stringify({
            total: totalFeedback,
            positive: positiveCount,
            negative: negativeCount
          }));

    - name: Generate feedback summary
      run: |
        echo "## Team Feedback Analysis" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "feedback-stats.json" ]; then
          total=$(cat feedback-stats.json | jq '.total')
          positive=$(cat feedback-stats.json | jq '.positive')
          negative=$(cat feedback-stats.json | jq '.negative')
          
          echo "- **Total Feedback Items**: $total" >> $GITHUB_STEP_SUMMARY
          echo "- **Positive Feedback**: $positive" >> $GITHUB_STEP_SUMMARY
          echo "- **Negative Feedback**: $negative" >> $GITHUB_STEP_SUMMARY
          
          if [ $total -gt 0 ]; then
            satisfaction=$((positive * 100 / total))
            echo "- **Satisfaction Rate**: $satisfaction%" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "- No feedback data available" >> $GITHUB_STEP_SUMMARY
        fi